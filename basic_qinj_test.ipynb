{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2526778c",
   "metadata": {},
   "source": [
    "before start the testing, see Readme, be sure the IPbus, control Hub and python 3.8 is installed.\n",
    "To properly set all paths run source setup.sh.\n",
    "\n",
    "## Cell 1: KCU Connection Setup\n",
    "This cell establishes connection to the KCU board and verifies basic communication.\n",
    "- Sets KCU IP address to 192.168.0.10\n",
    "- Enables control hub mode\n",
    "- Performs firmware version check and loopback test\n",
    "\n",
    "**Expected Output:** \n",
    "- \"Successfully connected to KCU\"\n",
    "- Firmware version information\n",
    "- \"KCU Loopback test PASSED\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tamalero.utils import get_kcu\n",
    "\n",
    "kcu_ip = \"192.168.0.10\" ## If your KCU ip is diff, modify it.\n",
    "\n",
    "kcu = get_kcu(\n",
    "    kcu_ip,\n",
    "    control_hub=True,\n",
    "    host='localhost',\n",
    "    verbose=False\n",
    ")\n",
    "print(\"Successfully connected to KCU.\")\n",
    "\n",
    "# Check the KCU's status and firmware\n",
    "#kcu.status() # Prints LpGBT link statuses from KCU \n",
    "fw_ver = kcu.get_firmware_version(verbose=True) #\n",
    "kcu.check_clock_frequencies(verbose=True) # Verifies KCU clock stability\n",
    "\n",
    "# Perform a simple loopback register test to confirm communication\n",
    "loopback_val = 0xABCD1234\n",
    "kcu.write_node(\"LOOPBACK.LOOPBACK\", loopback_val) #\n",
    "read_val = kcu.read_node(\"LOOPBACK.LOOPBACK\").value()\n",
    "if read_val == loopback_val:\n",
    "    print(f\"KCU Loopback test PASSED: Wrote 0x{loopback_val:X}, Read 0x{read_val:X}\")\n",
    "else:\n",
    "    print(f\"KCU Loopback test FAILED: Wrote 0x{loopback_val:X}, Read 0x{read_val:X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb2144",
   "metadata": {},
   "source": [
    "This cell configures the ReadoutBoard object and establishes lpGBT communication.\n",
    "\n",
    "Steps performed:\n",
    "1. Initialize ReadoutBoard with modulev1 configuration\n",
    "2. Detect and verify readout board version\n",
    "3. Check lpGBT link status\n",
    "4. Verify no FEC errors on DAQ link\n",
    "\n",
    "Troubleshooting:\n",
    "- If version detection fails, check lpGBT connection\n",
    "- If FEC errors > 0, reset error counters and check links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcaf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tamalero.ReadoutBoard import ReadoutBoard\n",
    "\n",
    "rb = ReadoutBoard(\n",
    "    rb=0,\n",
    "    kcu=kcu,\n",
    "    config=\"modulev1\", \n",
    "    trigger=False,     \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Readout Board version detected: {rb.ver}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1df252",
   "metadata": {},
   "source": [
    "- If FEC errors > 0, no worries, READOUT_BOARD_0.LPGBT.UPLINK_0.FEC_ERR_CNT was reset later\n",
    "READOUT_BOARD_0.LPGBT.UPLINK_1.FEC_ERR_CNT is red due to our current setup only have one uplink which is uplink 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking DAQ LpGBT base configuration:\")\n",
    "rb.DAQ_LPGBT.read_base_config() #\n",
    "\n",
    "# Read on-board temperatures\n",
    "print(\"\\nReading temperatures:\")\n",
    "rb.read_temp(verbose=True) #\n",
    "\n",
    "print(\"\\nReading DAQ LpGBT ADCs:\")\n",
    "try:\n",
    "    rb.DAQ_LPGBT.read_adcs(check=True, strict_limits=True) #\n",
    "except ValueError as e:\n",
    "    print(f\"LpGBT ADC check issue: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\nDAQ LpGBT Link Good: {rb.DAQ_LPGBT.link_status()}\") \n",
    "fec_errors = rb.get_FEC_error_count() # Reads KCU registers defined in READOUT_BOARD.xml\n",
    "print(f\"FEC Errors: DAQ LpGBT = {fec_errors.get('DAQ', 'N/A')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e7396",
   "metadata": {},
   "source": [
    "Init ETROC2, our etroc2 i2c address is 0x63 and i2c channel is 1, modify it if yours diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tamalero.ETROC import ETROC\n",
    "from tamalero.colors import green, red, yellow\n",
    "from tamalero.LPGBT import LPGBT\n",
    "import time\n",
    "\n",
    "etroc_elinks_map = {0: [0, 4, 8, 12]} # should map your design\n",
    "print(\"Initializing ETROC objects...\")\n",
    "my_etroc2s = [ \n",
    "    ETROC(\n",
    "    rb,\n",
    "    master='lpgbt',\n",
    "    i2c_adr=0x63,\n",
    "    chip_id=63,                 \n",
    "    i2c_channel=1,\n",
    "    elinks=etroc_elinks_map,\n",
    "    strict=False,\n",
    "    verbose=True,\n",
    "    ),\n",
    "    ETROC(\n",
    "    rb,\n",
    "    master='lpgbt',\n",
    "    i2c_adr=0x62,\n",
    "    chip_id=62,                 \n",
    "    i2c_channel=1,\n",
    "    elinks=etroc_elinks_map,\n",
    "    strict=False,\n",
    "    verbose=True \n",
    "    ),\n",
    "    ETROC(\n",
    "    rb,\n",
    "    master='lpgbt',\n",
    "    i2c_adr=0x61,\n",
    "    chip_id=61,                  \n",
    "    i2c_channel=1,\n",
    "    elinks=etroc_elinks_map,\n",
    "    strict=False,\n",
    "    verbose=True \n",
    "    ),\n",
    "    ETROC(\n",
    "    rb,\n",
    "    master='lpgbt',\n",
    "    i2c_adr=0x60,\n",
    "    chip_id=60,                 \n",
    "    i2c_channel=1,\n",
    "    elinks=etroc_elinks_map,\n",
    "    strict=False,\n",
    "    verbose=True \n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_etroc2 in my_etroc2s:\n",
    "    print(\"------------Board------------\")\n",
    "    if not my_etroc2.is_connected():\n",
    "        raise ConnectionError(\"Failed to connect to ETROC2 via I2C.\")\n",
    "\n",
    "    print(green(\"SUCCESS: I2C communication with ETROC2 is established.\"))\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Verifying a key configuration register...\")\n",
    "    register_to_check = 'disScrambler'\n",
    "    expected_value = 1\n",
    "\n",
    "    read_back_value = my_etroc2.rd_reg(register_to_check)\n",
    "    print(f\"Reading back '{register_to_check}' register...\")\n",
    "    print(f\"  - Value Expected: {expected_value}\")\n",
    "    print(f\"  - Value Read Back: {read_back_value}\")\n",
    "\n",
    "    if read_back_value == expected_value:   ## check etroc register can be read correctly\n",
    "        print(green(\"  - SUCCESS: Register read-back matches expected value.\"))\n",
    "    else:\n",
    "        print(red(\"  - FAILURE: Register read-back does NOT match expected value.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c4c0c",
   "metadata": {},
   "source": [
    "Just checking etroc status and see which elink is locked.\n",
    "if elink is unlock, can't retrieve data from etroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_etroc2 in my_etroc2s:\n",
    "    print(\"------------Board------------\")\n",
    "    \n",
    "    print(f\"ETROC connected: {my_etroc2.is_connected()}\")\n",
    "    print(f\"ETROC version: {my_etroc2.get_ver()}\")\n",
    "\n",
    "    # Check if ETROC is in a good state\n",
    "    if hasattr(my_etroc2, 'is_good'):\n",
    "        print(f\"ETROC is good: {my_etroc2.is_good()}\")\n",
    "\n",
    "    # Check controller state\n",
    "    if hasattr(my_etroc2, 'controllerState'):\n",
    "        state = my_etroc2.rd_reg(\"controllerState\")\n",
    "        print(f\"Controller state: {state} (should be 11)\")\n",
    "\n",
    "    # Check Pll lock status\n",
    "    Pll_state = my_etroc2.rd_reg(\"pllUnlockCount\")\n",
    "    print(f\"PLL Unlock Count: {Pll_state} (should be 0 or very few and would not increase)\")\n",
    "\n",
    "    # Check elink lock status\n",
    "    print(\"\\n=== Elink Status ===\")\n",
    "    elink_status = my_etroc2.get_elink_status()\n",
    "    print(f\"Elink status: {elink_status}\")\n",
    "\n",
    "\n",
    "    for elink in [0, 4, 8, 12]: \n",
    "        locked = rb.etroc_locked(elink, slave=False)\n",
    "        print(f\"Elink {elink} locked: {locked}\")\n",
    "        \n",
    "        if locked:\n",
    "            packet_count = rb.read_packet_count(elink, slave=False)\n",
    "            error_count = rb.read_error_count(elink, slave=False)\n",
    "            filler_rate = rb.read_filler_rate(elink, slave=False)\n",
    "            \n",
    "            print(f\"  Packets: {packet_count}\")\n",
    "            print(f\"  Errors: {error_count}\")\n",
    "            print(f\"  Filler rate: {filler_rate}\")\n",
    "            \n",
    "    print('-' * 50)\n",
    "    eprx_group_to_check = [0,1,2,3]\n",
    "        \n",
    "    try:\n",
    "        for group in eprx_group_to_check:\n",
    "            # Read the Read-Only status register\n",
    "            dll_locked_status = rb.DAQ_LPGBT.rd_reg(f\"LPGBT.RO.EPORTRX_RO.EPRX.EPRX{group}DLLLOCKED\")\n",
    "            if dll_locked_status == 1:\n",
    "                print(green(f\"  - LpGBT EPRX Group {group} DLL Lock Status: {dll_locked_status} (Locked)\"))\n",
    "            else:\n",
    "                print(red(f\"  - LpGBT EPRX Group {group} DLL Lock Status: {dll_locked_status} (NOT Locked)\"))\n",
    "    except Exception as e:\n",
    "        print(red(f\"dddCould not read LpGBT EPRX DLL status. Error: {e}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f93e2a",
   "metadata": {},
   "source": [
    "check uplink status and rese FEC errors if not 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7045a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Check Uplink Status ===\")\n",
    "\n",
    "# Check uplink error counts\n",
    "uplink0_errors = rb.kcu.read_node(f\"READOUT_BOARD_{rb.rb}.LPGBT.UPLINK_0.FEC_ERR_CNT\").value()\n",
    "\n",
    "print(f\"Uplink 0 FEC errors: {uplink0_errors}\")\n",
    "\n",
    "# Check uplink ready status\n",
    "uplink0_ready = rb.kcu.read_node(f\"READOUT_BOARD_{rb.rb}.LPGBT.UPLINK_0.READY\").value()\n",
    "\n",
    "print(f\"Uplink 0 ready: {uplink0_ready}\")\n",
    "\n",
    "# Reset FEC error counters\n",
    "print(\"\\nResetting FEC error counters...\")\n",
    "rb.reset_FEC_error_count()\n",
    "\n",
    "print(\"\\nChecking elink 12 status again...\")\n",
    "rb.reset_data_error_count()\n",
    "time.sleep(1)\n",
    "\n",
    "for elinks in [0, 4, 8, 12]:  # we current only have elink 12 locked\n",
    "    locked = rb.etroc_locked(12, slave=False)\n",
    "    packet_count = rb.read_packet_count(elinks, slave=False)\n",
    "    error_count = rb.read_error_count(elinks, slave=False)\n",
    "    filler_rate = rb.read_filler_rate(elinks, slave=False)\n",
    "\n",
    "    print(f\"Elink {elinks} - Locked: {locked}, Packets: {packet_count}, Errors: {error_count}, Filler: {filler_rate}\")\n",
    "\n",
    "    if filler_rate > 15000000 and error_count < 100:\n",
    "        print(f\"Elink {elinks} appears to be working!\")\n",
    "    else:\n",
    "        print(f\"Elink {elinks} still has issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad886e",
   "metadata": {},
   "source": [
    "just make sure lpGBT assignment is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Verify lpGBT Assignment ===\")\n",
    "\n",
    "print(\"Checking master vs slave elink locks...\")\n",
    "\n",
    "# Check master elinks (lpgbt=0)\n",
    "master_locked = rb.kcu.read_node(f\"READOUT_BOARD_{rb.rb}.ETROC_LOCKED\").value()\n",
    "print(f\"Master (lpgbt=0) elinks locked: {bin(master_locked)}\")\n",
    "\n",
    "# Check slave elinks (lpgbt=1) \n",
    "slave_locked = rb.kcu.read_node(f\"READOUT_BOARD_{rb.rb}.ETROC_LOCKED_SLAVE\").value()\n",
    "print(f\"Slave (lpgbt=1) elinks locked: {bin(slave_locked)}\")\n",
    "\n",
    "for elink in [0, 4, 8, 12, 14]:\n",
    "    print(f\"\\nElink {elink}:\")\n",
    "\n",
    "    locked_master = rb.etroc_locked(elink, slave=False)\n",
    "    print(f\"  lpgbt=0: {locked_master}\")\n",
    "    \n",
    "    locked_slave = rb.etroc_locked(elink, slave=True)\n",
    "    print(f\"  lpgbt=1: {locked_slave}\")\n",
    "    \n",
    "    if locked_master:\n",
    "        print(f\"  → Elink {elink} is on lpgbt=0 (DAQ)\")\n",
    "    elif locked_slave:\n",
    "        print(f\"  → Elink {elink} is on lpgbt=1 (Trigger)\")\n",
    "    else:\n",
    "        print(f\"  → Elink {elink} not locked on either lpGBT\")\n",
    "\n",
    "for my_etroc2 in my_etroc2s:\n",
    "    print(\"------------Board------------\")\n",
    "    print(f\"\\n2. Your ETROC elinks configuration:\")\n",
    "    print(f\"elinks[0]: {my_etroc2.elinks.get(0, 'Not configured')}\")\n",
    "    print(f\"elinks[1]: {my_etroc2.elinks.get(1, 'Not configured')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bba024",
   "metadata": {},
   "source": [
    "try to reproduce data from ETROC without charge injection\n",
    "under workmode : 0(normal mode) data type should be only contain header and trailer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_etroc2 in my_etroc2s:\n",
    "    print(\"------------Board------------\")\n",
    "    my_etroc2.set_power_mode(mode=\"high\", row=0, col=0, broadcast=True)\n",
    "    my_etroc2.run_threshold_scan(offset=15, use=True, out_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1133887",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_etroc2 in my_etroc2s:\n",
    "    print(\"------------Board------------\")\n",
    "    my_etroc2.plot_threshold(outdir='results/', noise_width=True)\n",
    "    my_etroc2.plot_threshold(outdir='results/', noise_width=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clks = [0,0,0,0]\n",
    "datas = [0,0,0,0]\n",
    "invs = [0,0,1,0]\n",
    "for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "    print(\"------------Board------------\")\n",
    "    print(i, my_etroc2.FC_status(), my_etroc2.get_invalidFCCount())\n",
    "    if(invs[i]):\n",
    "        my_etroc2.wr_reg('FC_InvData', 1)\n",
    "    else:\n",
    "        my_etroc2.wr_reg('FC_InvData', 0)\n",
    "\n",
    "    my_etroc2.reset_fast_command()\n",
    "    \n",
    "    # my_etroc2.wr_reg('asyAlignFastcommand', 0)\n",
    "    # if(clks[i]):\n",
    "    #     my_etroc2.enable_fcClkDelay()\n",
    "    # else:\n",
    "    #     my_etroc2.disable_fcClkDelay()\n",
    "    # if(datas[i]):\n",
    "    #     my_etroc2.enable_fcDataDelay()\n",
    "    # else:\n",
    "    #     my_etroc2.disable_fcDataDelay()\n",
    "    print(i, my_etroc2.FC_status(), my_etroc2.get_invalidFCCount())\n",
    "    print(i, my_etroc2.FC_status(), my_etroc2.get_invalidFCCount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea846ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "    print(\"------------Board------------\")\n",
    "    print(i, my_etroc2.FC_status(), my_etroc2.get_invalidFCCount())\n",
    "    print(i, my_etroc2.FC_status(), my_etroc2.get_invalidFCCount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tamalero.FIFO import FIFO\n",
    "from tamalero.DataFrame import DataFrame\n",
    "\n",
    "print(\"\\n=== Get data with charge injection ===\")\n",
    "df = DataFrame()\n",
    "fifo = FIFO(rb)\n",
    "\n",
    "fifo.reset()\n",
    "rb.reset_data_error_count()\n",
    "rb.enable_etroc_readout()\n",
    "rb.rerun_bitslip()  \n",
    "fifo.use_etroc_data()\n",
    "time.sleep(1)\n",
    "\n",
    "delays = [501, 501, 501, 501]\n",
    "pixels_to_test = [(12, 8)]\n",
    "\n",
    "rb.DAQ_LPGBT.set_uplink_group_data_source(\"normal\") \n",
    "for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "    my_etroc2.reset()\n",
    "    my_etroc2.disable_QInj(broadcast=True)\n",
    "    my_etroc2.disable_data_readout(broadcast=True)\n",
    "    my_etroc2.disable_trigger_readout(broadcast=True)\n",
    "    for (pixel_row,pixel_col) in pixels_to_test:\n",
    "        my_etroc2.QInj_set(charge=30, delay=10, L1Adelay=delays[i], row=pixel_row, col=pixel_col, broadcast=False, reset=True)\n",
    "    pixels_to_test = pixels_to_test + [(pixels_to_test[-1][0]+1,pixels_to_test[-1][1]+1)]\n",
    "\n",
    "print(green(\"Configuration complete.\"))\n",
    "# fifo.send_l1a(4096)  ## l1a value based on test_ETROC.py\n",
    "fifo.send_QInj(1000, delay=my_etroc2.QINJ_delay)\n",
    "\n",
    "try:\n",
    "    data = fifo.pretty_read(df)\n",
    "    occupancy = len(data)\n",
    "    if occupancy > 0:\n",
    "        print(green(\"SUCCESS: Data is being generated!\"))\n",
    "        print(f\"   FIFO returned {occupancy} data items\")\n",
    "\n",
    "        for j, word in enumerate(data[:24]):\n",
    "            data_type, event_data = word[0], word[1]\n",
    "            print(f\"  Event {j}: {data_type} -> {event_data}\")\n",
    "           \n",
    "except Exception as e:\n",
    "    print(red(f\"Read failed: {e}\"))\n",
    "\n",
    "finally:\n",
    "    print(\"\\nCleaning up...\")\n",
    "    for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "        my_etroc2.disable_QInj(broadcast=True)\n",
    "        my_etroc2.disable_data_readout(broadcast=True)\n",
    "        my_etroc2.disable_trigger_readout(broadcast=True)\n",
    "    print(\"Test complete!\")\n",
    "\n",
    "\n",
    "# fifo.set_trigger_rate(1000)\n",
    "# time.sleep(5)\n",
    "# fifo.set_trigger_rate(0)\n",
    "\n",
    "\n",
    "# occupancy = fifo.get_occupancy()\n",
    "# lost_words = fifo.get_lost_word_count()\n",
    "\n",
    "# print(f\"Occupancy after continuous trigger: {occupancy}\")\n",
    "# print(f\"Lost words: {lost_words}\")\n",
    "# time.sleep(1)\n",
    "\n",
    "\n",
    "# if occupancy > 0 or lost_words > 0:\n",
    "#     print(\"SUCCESS: Data is being generated!\")\n",
    "#     try:\n",
    "#         # Use the simple read method\n",
    "#         raw_data = fifo.read(dispatch=True)\n",
    "#         print(f\"✅ Successfully read {len(raw_data)} words!\")\n",
    "            \n",
    "#         if len(raw_data) >= 2:\n",
    "#             from tamalero.FIFO import merge_words\n",
    "#             merged = merge_words(raw_data[:20]) \n",
    "                \n",
    "#             print(f\"Merged {len(merged)} events:\")\n",
    "#             for j, word in enumerate(merged[:10]):\n",
    "#                 data_type, event_data = df.read(word)\n",
    "                \n",
    "#                 print(f\"  Event {j}: {data_type} -> {event_data}\")\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Read failed: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "charge = 30\n",
    "pixels_to_test = [(12, 8)]\n",
    "output_dir = \"Qinj_Output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_dat_file = os.path.join(output_dir, f\"qinj_{charge}fC.dat\")\n",
    "\n",
    "print(\"=== Charge Injection Test ===\")\n",
    "print(f\"Charge: {charge} fC\")\n",
    "print(f\"Saving raw data to: {output_dat_file}\")\n",
    "\n",
    "# Enable readout only for the pixel under test\n",
    "# Set charge injection parameters\n",
    "delays = [501, 501, 501, 501]\n",
    "for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "    my_etroc2.reset()\n",
    "    my_etroc2.disable_QInj(broadcast=True)\n",
    "    my_etroc2.disable_data_readout(broadcast=True)\n",
    "    my_etroc2.disable_trigger_readout(broadcast=True)\n",
    "    for (pixel_row,pixel_col) in pixels_to_test:\n",
    "        my_etroc2.QInj_set(charge=30, delay=10, L1Adelay=delays[i], row=pixel_row, col=pixel_col, broadcast=False, reset=True)\n",
    "    pixels_to_test = pixels_to_test + [(pixels_to_test[-1][0]+1,pixels_to_test[-1][1]+1)]\n",
    "# # The QSel register takes a value from 0-31 to represent 1-32 fC\n",
    "# my_etroc2.wr_reg(\"QSel\", charge - 1, row=pixel_row, col=pixel_col)\n",
    "# my_etroc2.wr_reg(\"QInjEn\", 1, row=pixel_row, col=pixel_col) #enable charge injection\n",
    "print(green(\"Configuration complete.\"))\n",
    "\n",
    "fifo = FIFO(rb)\n",
    "fifo.reset()\n",
    "rb.reset_data_error_count()\n",
    "rb.enable_etroc_readout()\n",
    "rb.rerun_bitslip()  \n",
    "fifo.use_etroc_data()\n",
    "time.sleep(1)\n",
    "\n",
    "try:\n",
    "    fifo.send_QInj(500, delay=my_etroc2.QINJ_delay)\n",
    "    raw_data = fifo.read(dispatch=True)\n",
    "    print(green(f\"✅ Successfully read {len(raw_data)} words from the FIFO.\"))\n",
    "\n",
    "    # --- Save Raw Data ---\n",
    "    with open(output_dat_file, \"wb\") as f:\n",
    "        f.write(struct.pack('<{}I'.format(len(raw_data)), *raw_data))\n",
    "    print(green(f\"✅ Raw data saved to {output_dat_file}\"))\n",
    "\n",
    "except Exception as e:\n",
    "    print(red(f\"An error occurred: {e}\"))\n",
    "\n",
    "finally:\n",
    "    # --- Cleanup ---\n",
    "    print(\"\\nCleaning up...\")\n",
    "    for i,my_etroc2 in enumerate(my_etroc2s):\n",
    "        my_etroc2.disable_QInj(broadcast=True)\n",
    "        my_etroc2.disable_data_readout(broadcast=True)\n",
    "        my_etroc2.disable_trigger_readout(broadcast=True)\n",
    "    print(\"Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "import json\n",
    "from tamalero.DataFrame import DataFrame\n",
    "from tamalero.colors import green, red\n",
    "\n",
    "def merge_words(res):\n",
    "    empty_frame_mask = np.array(res[0::2]) > (2**8)\n",
    "    len_cut = min(len(res[0::2]), len(res[1::2]))\n",
    "    if len(res) > 0:\n",
    "        return list(np.array(res[0::2])[:len_cut][empty_frame_mask[:len_cut]] | (np.array(res[1::2]) << 32)[:len_cut][empty_frame_mask[:len_cut]])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def _aggregate_fragments(fragments):\n",
    "    \"\"\"\n",
    "    Helper function to combine a list of event fragments into a single event record.\n",
    "    This version now correctly handles cases where trailers (and chipid) are missing.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(fragments)\n",
    "    \n",
    "    headers = df[df['l1counter'].notna()]\n",
    "    hits = df[df['toa'].notna()]\n",
    "    \n",
    "    # Robustly handle missing trailers\n",
    "    if 'chipid' in df.columns:\n",
    "        trailers = df[df['chipid'].notna()]\n",
    "    else:\n",
    "        # If no trailers exist in this fragment, create an empty DataFrame\n",
    "        trailers = pd.DataFrame()\n",
    "\n",
    "    all_hits = {\n",
    "        'row_id': [], 'col_id': [], 'toa_code': [], 'tot_code': [],\n",
    "        'cal_code': [], 'elink': [], 'chip_id': []\n",
    "    }\n",
    "\n",
    "    for elink in hits['elink'].unique():\n",
    "        elink_hits = hits[hits['elink'] == elink]\n",
    "        \n",
    "        # Only look for trailers if the trailers DataFrame is not empty\n",
    "        if not trailers.empty:\n",
    "            elink_trailer = trailers[trailers['elink'] == elink]\n",
    "            chip_id = int(elink_trailer['chipid'].iloc[0]) if not elink_trailer.empty else -1\n",
    "        else:\n",
    "            chip_id = -1 # No trailer found for this event at all\n",
    "        \n",
    "        all_hits['row_id'].extend(elink_hits['row_id'].tolist())\n",
    "        all_hits['col_id'].extend(elink_hits['col_id'].tolist())\n",
    "        all_hits['toa_code'].extend(elink_hits['toa'].tolist())\n",
    "        all_hits['tot_code'].extend(elink_hits['tot'].tolist())\n",
    "        all_hits['cal_code'].extend(elink_hits['cal'].tolist())\n",
    "        all_hits['elink'].extend(elink_hits['elink'].tolist())\n",
    "        all_hits['chip_id'].extend([chip_id] * len(elink_hits))\n",
    "\n",
    "    return {\n",
    "        'bcid': int(headers['bcid'].iloc[0]) if not headers.empty else -1,\n",
    "        'l1counters': headers['l1counter'].tolist(),\n",
    "        'nhits': len(all_hits['row_id']),\n",
    "        **all_hits,\n",
    "    }\n",
    "\n",
    "def process_and_merge_dat_file(input_dat_file, bcid_window=10):\n",
    "    output_json_file = os.path.splitext(input_dat_file)[0] + \"_merged.json\"\n",
    "    \n",
    "    print(f\"\\n-> Reading raw data from: {input_dat_file}\")\n",
    "    df_decoder = DataFrame('ETROC2')\n",
    "\n",
    "    try:\n",
    "        with open(input_dat_file, 'rb') as f:\n",
    "            bin_data = f.read()\n",
    "            raw_data = struct.unpack(f'<{int(len(bin_data)/4)}I', bin_data)\n",
    "    except FileNotFoundError:\n",
    "        print(red(f\"ERROR: Input file not found at '{input_dat_file}'\"))\n",
    "        return None, None\n",
    "\n",
    "    merged_data = merge_words(raw_data)\n",
    "    unpacked_data = [df_decoder.read(x) for x in merged_data]\n",
    "    print(f\"-> Unpacked {len(unpacked_data)} data words.\")\n",
    "\n",
    "    events, current_event_fragments = [], []\n",
    "    for data_type, data_dict in unpacked_data:\n",
    "        if data_type == 'header':\n",
    "            if not current_event_fragments:\n",
    "                current_event_fragments.append(data_dict)\n",
    "            else:\n",
    "                bcid_diff = abs(current_event_fragments[0]['bcid'] - data_dict['bcid'])\n",
    "                bcid_diff = min(bcid_diff, 3564 - bcid_diff)\n",
    "                if bcid_diff < bcid_window:\n",
    "                    current_event_fragments.append(data_dict)\n",
    "                else:\n",
    "                    events.append(_aggregate_fragments(current_event_fragments))\n",
    "                    current_event_fragments = [data_dict]\n",
    "        elif current_event_fragments:\n",
    "            current_event_fragments.append(data_dict)\n",
    "    if current_event_fragments:\n",
    "        events.append(_aggregate_fragments(current_event_fragments))\n",
    "\n",
    "    events_ak = ak.Array(events)\n",
    "    print(green(f\"-> Successfully merged into {len(events_ak)} events.\"))\n",
    "\n",
    "    with open(output_json_file, \"w\") as f:\n",
    "        f.write(ak.to_json(events_ak))\n",
    "    print(green(f\"✅ Final merged data saved to: {output_json_file}\"))\n",
    "    \n",
    "    return events_ak, output_json_file\n",
    "\n",
    "# if 'output_dat_file' in locals() and os.path.exists(output_dat_file):\n",
    "#     output_json_file = os.path.splitext(output_dat_file)[0] + \"_merged.json\"\n",
    "#     process_and_merge_by_bcid(output_dat_file, output_json_file)\n",
    "# else:\n",
    "#     print(red(\"Error: Could not find the `output_dat_file` variable or the file itself.\"))\n",
    "#     print(red(\"Please make sure you have run the previous data acquisition cell successfully.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250edf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dat_file:\n",
    "    final_events, saved_json_path = process_and_merge_dat_file(output_dat_file)\n",
    "\n",
    "    if final_events is not None:\n",
    "        print(\"\\n--- First 5 Merged Events from output file ---\")\n",
    "        for i, event in enumerate(final_events[:5]):\n",
    "            print(f\"\\nEvent {i} (BCID: {event['bcid']}):\")\n",
    "            print(f\"  L1A Counters from modules: {event['l1counters']}\")\n",
    "            print(f\"  Total Hits in event: {event['nhits']}\")\n",
    "            for j in range(event['nhits']):\n",
    "                 print(f\"    - Hit {j+1}: [Elink: {event['elink'][j]}, Chip ID: {event['chip_id'][j]}, Row: {event['row_id'][j]}, Col: {event['col_id'][j]}, ToT: {event['tot_code'][j]}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc589d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a912a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
