{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6762ca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETROC COSMIC RUN TEST - HARDWARE INITIALIZAATION\n",
      "IPBus address: chtcp-2.0://localhost:10203?target=192.168.0.10:50001\n",
      "KCU firmware version: 3.2.4\n",
      "\u001b[92mSuccessfully connected to KCU.\u001b[0m\n",
      "LPGBT Link Status from KCU:\n",
      "\u001b[92m0x2021  r       READOUT_BOARD_0.LPGBT.DOWNLINK.READY              0x00000001\u001b[0m\n",
      "\u001b[91m0x2001  r       READOUT_BOARD_0.LPGBT.UPLINK_0.READY              0x00000000\u001b[0m\n",
      "\u001b[91m0x2001  r       READOUT_BOARD_0.LPGBT.UPLINK_0.FEC_ERR_CNT        0x0000FFFF\u001b[0m\n",
      "\u001b[92mKCU Loopback test PASSED: Wrote 0xABCD1234, Read 0xABCD1234\u001b[0m\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "1\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "2\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "3\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "4\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "5\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "6\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "7\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "8\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "9\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "10\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "11\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "12\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "13\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "14\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "15\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "16\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "17\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "18\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "19\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "20\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "21\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "22\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "23\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "24\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "25\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "26\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "27\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "28\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "29\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "30\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "31\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "32\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "33\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "34\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "35\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "36\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "37\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "38\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "39\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "40\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "41\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "42\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "43\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "44\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "45\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "46\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "47\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "48\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "49\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "50\n",
      "0x1d7 readback value is 0x00\n",
      "lpGBT version found False\n",
      "51\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Could not successfully read from lpGBT and failed to determine lpGBT version. Check optical links and power of RB.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(red(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKCU Loopback test FAILED: Wrote 0x\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloopback_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mX\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Read 0x\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mread_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mX\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# ======================================================================================\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 2. INITIALIZE READOUT BOARD\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# ======================================================================================\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m rb \u001b[38;5;241m=\u001b[39m \u001b[43mReadoutBoard\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREADOUTBOARD_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkcu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkcu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREADOUTBOARD_CONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrigger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_bad_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(green(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadout Board version detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrb\u001b[38;5;241m.\u001b[39mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# ======================================================================================\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 3. INITIALIZE FOUR ETROC\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# ======================================================================================\u001b[39;00m\n",
      "File \u001b[0;32m~/yf_temp/tamalero/tamalero/ReadoutBoard.py:43\u001b[0m, in \u001b[0;36mReadoutBoard.__init__\u001b[0;34m(self, rb, trigger, flavor, kcu, config, alignment, data_mode, etroc, verbose, allow_bad_links, poke)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger \u001b[38;5;241m=\u001b[39m trigger\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# print('############################ReadoutBoard LPGBT Instantiation############################')\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDAQ_LPGBT \u001b[38;5;241m=\u001b[39m \u001b[43mLPGBT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkcu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoke\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrbver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print('############################ReadoutBoard VTRX Instantiation############################')\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVTRX \u001b[38;5;241m=\u001b[39m VTRX(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDAQ_LPGBT)\n",
      "File \u001b[0;32m~/yf_temp/tamalero/tamalero/LPGBT.py:70\u001b[0m, in \u001b[0;36mLPGBT.__init__\u001b[0;34m(self, rb, trigger, flavor, master, kcu, do_adc_calibration, config, debug, ver, verbose, poke, rbver)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m poke:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_adc_calibration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_adc_calibration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "File \u001b[0;32m~/yf_temp/tamalero/tamalero/LPGBT.py:147\u001b[0m, in \u001b[0;36mLPGBT.configure\u001b[0;34m(self, do_adc_calibration)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(timeout)\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not successfully read from lpGBT and failed to determine lpGBT version. Check optical links and power of RB.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_v0 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_v1 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_v2:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m > lpGBT v0 detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Could not successfully read from lpGBT and failed to determine lpGBT version. Check optical links and power of RB."
     ]
    }
   ],
   "source": [
    "from tamalero.FIFO import FIFO\n",
    "from tamalero.ETROC import ETROC\n",
    "from tamalero.LPGBT import LPGBT\n",
    "from tamalero.utils import get_kcu\n",
    "from tamalero.DataFrame import DataFrame\n",
    "from tamalero.colors import green, red, yellow\n",
    "from tamalero.ReadoutBoard import ReadoutBoard\n",
    "import os\n",
    "import sys\n",
    "import tty\n",
    "import time\n",
    "import select\n",
    "import pickle\n",
    "import termios\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "KCU_IP = \"192.168.0.10\" ## If your KCU ip is diff, modify it.\n",
    "\n",
    "READOUTBOARD_ID = 0\n",
    "READOUTBOARD_CONFIG = 'default'\n",
    "\n",
    "ETROC_I2C_ADDRESSES = [0x63, 0x62, 0x61, 0x60]\n",
    "ETROC_I2C_CHANNEL = 1\n",
    "ETROC_ELINKS_MAP = {0: [0, 4, 8, 12]}\n",
    "\n",
    "\n",
    "print('ETROC COSMIC RUN TEST - HARDWARE INITIALIZAATION')\n",
    "\n",
    "\n",
    "kcu = get_kcu(\n",
    "    KCU_IP,\n",
    "    control_hub=True,\n",
    "    host='localhost',\n",
    "    verbose=False\n",
    ")\n",
    "print(green(\"Successfully connected to KCU.\"))\n",
    "\n",
    "kcu.status() # Prints LpGBT link statuses from KCU \n",
    "# fw_ver = kcu.get_firmware_version() #\n",
    "# kcu.check_clock_frequencies() # Verifies KCU clock stability\n",
    "\n",
    "# Perform a simple loopback register test to confirm communication\n",
    "loopback_val = 0xABCD1234\n",
    "kcu.write_node(\"LOOPBACK.LOOPBACK\", loopback_val) #\n",
    "read_val = kcu.read_node(\"LOOPBACK.LOOPBACK\").value()\n",
    "\n",
    "if read_val == loopback_val:\n",
    "    print(green(f\"KCU Loopback test PASSED: Wrote 0x{loopback_val:X}, Read 0x{read_val:X}\"))\n",
    "else:\n",
    "    print(red(f\"KCU Loopback test FAILED: Wrote 0x{loopback_val:X}, Read 0x{read_val:X}\"))\n",
    "\n",
    "# ======================================================================================\n",
    "# 2. INITIALIZE READOUT BOARD\n",
    "# ======================================================================================\n",
    "rb = ReadoutBoard(\n",
    "    rb=READOUTBOARD_ID,\n",
    "    kcu=kcu,\n",
    "    config=READOUTBOARD_CONFIG, \n",
    "    trigger=False,     \n",
    "    verbose=False,\n",
    "    allow_bad_links=True\n",
    ")\n",
    "print(green(f\"Readout Board version detected: {rb.ver}\"))\n",
    "\n",
    "# ======================================================================================\n",
    "# 3. INITIALIZE FOUR ETROC\n",
    "# ======================================================================================\n",
    "\n",
    "print(\"\\n3. Initializing ETROC chips...\")\n",
    "etroc_chips = []\n",
    "chip_names = []\n",
    "\n",
    "for i, addr in enumerate(ETROC_I2C_ADDRESSES):\n",
    "    chip_name = f\"Chip{i+1}\"\n",
    "    chip_names.append(chip_name)\n",
    "    \n",
    "    print(f\"\\nInitializing {chip_name} (I2C: 0x{addr:02X})...\")\n",
    "    \n",
    "    try:\n",
    "        etroc = ETROC(\n",
    "            rb,\n",
    "            master='lpgbt',\n",
    "            i2c_adr=addr,\n",
    "            i2c_channel=ETROC_I2C_CHANNEL,\n",
    "            elinks=ETROC_ELINKS_MAP,\n",
    "            strict=False,\n",
    "            verbose=True\n",
    "        )\n",
    "        etroc_chips.append(etroc)\n",
    "        \n",
    "        # Verify communication\n",
    "        if etroc.is_connected():\n",
    "            # Check key registers\n",
    "            scrambler_status = etroc.rd_reg(\"disScrambler\")\n",
    "            controller_state = etroc.rd_reg(\"controllerState\")\n",
    "            pll_unlock_count = etroc.rd_reg(\"pllUnlockCount\")\n",
    "            \n",
    "            print(green(f\"✓ {chip_name} connected successfully\"))\n",
    "            print(f\"  Controller state: {controller_state} (should be 11)\")\n",
    "            print(f\"  PLL unlock count: {pll_unlock_count}\")\n",
    "            \n",
    "            if scrambler_status == 1:\n",
    "                print(green(\"  ✓ Register communication verified\"))\n",
    "            else:\n",
    "                print(red(\"  ✗ Register communication issue\"))\n",
    "        else:\n",
    "            print(red(f\"✗ {chip_name} not responding\"))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(red(f\"✗ Failed to initialize {chip_name}: {e}\"))\n",
    "        etroc_chips.append(None)\n",
    "\n",
    "print(green(\"\\n✓ Hardware initialization completed successfully!\"))\n",
    "print(f\"Initialized {len([c for c in etroc_chips if c is not None])} ETROC chips\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc1514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETROC COSMIC RUN TEST - QINJ ONLY AND DATA ACQUISITION\n",
      "\n",
      "1. Generating test pixel configuration...\n",
      "Test pixel assignments:\n",
      "  Chip1: [(0, 4)]\n",
      "  Chip2: [(6, 10), (7, 8)]\n",
      "  Chip3: [(15, 4), (15, 10)]\n",
      "  Chip4: [(5, 15)]\n",
      "\n",
      "2. Calibrating pixel baselines...\n",
      "\n",
      "Scanning Chip1...\n",
      "  Calibrating pixel (0, 4)...\n",
      "    Baseline: 548.0, Noise width: 5.0\n",
      "\n",
      "Scanning Chip2...\n",
      "  Calibrating pixel (6, 10)...\n",
      "    Baseline: 531.0, Noise width: 4.0\n",
      "  Calibrating pixel (7, 8)...\n",
      "    Baseline: 527.0, Noise width: 4.0\n",
      "\n",
      "Scanning Chip3...\n",
      "  Calibrating pixel (15, 4)...\n",
      "    Baseline: 548.0, Noise width: 5.0\n",
      "  Calibrating pixel (15, 10)...\n",
      "    Baseline: 561.0, Noise width: 5.0\n",
      "\n",
      "Scanning Chip4...\n",
      "  Calibrating pixel (5, 15)...\n",
      "    Baseline: 388.0, Noise width: 3.0\n",
      "\u001b[92mBaseline calibration completed\u001b[0m\n",
      "\n",
      "3. Configuring pixels for charge injection...\n",
      "Resetting Chip1...\n",
      "Resetting Chip2...\n",
      "Resetting Chip3...\n",
      "Resetting Chip4...\n",
      "\n",
      "Configuring Chip1 pixels...\n",
      "  Configuring pixel (0, 4)\n",
      "    DAC: 598, Charge: 30 fC\n",
      "\n",
      "Configuring Chip2 pixels...\n",
      "  Configuring pixel (6, 10)\n",
      "    DAC: 581, Charge: 30 fC\n",
      "  Configuring pixel (7, 8)\n",
      "    DAC: 577, Charge: 30 fC\n",
      "\n",
      "Configuring Chip3 pixels...\n",
      "  Configuring pixel (15, 4)\n",
      "    DAC: 598, Charge: 30 fC\n",
      "  Configuring pixel (15, 10)\n",
      "    DAC: 611, Charge: 30 fC\n",
      "\n",
      "Configuring Chip4 pixels...\n",
      "  Configuring pixel (5, 15)\n",
      "    DAC: 438, Charge: 30 fC\n",
      "\u001b[92mPixel configuration completed\u001b[0m\n",
      "\n",
      "4. Configuring self-trigger system...\n",
      "Trigger Enable Mask: 0x8\n",
      "Trigger Data Size: 1\n",
      "Trigger Delay Sel: 472\n",
      "elink: 0 locked status: True\n",
      "elink: 4 locked status: True\n",
      "elink: 8 locked status: True\n",
      "elink: 12 locked status: True\n",
      "\u001b[92mSelf-trigger system configured and enabled\u001b[0m\n",
      "\n",
      "5. Running data acquisition (1000 charge injections)...\n",
      "\u001b[92m✓ FIFO returned 0 data items\u001b[0m\n",
      "\u001b[91mNo data received from FIFO\u001b[0m\n",
      "\n",
      "8. Cleaning up system...\n",
      "Cleaning up Chip1...\n",
      "Cleaning up Chip2...\n",
      "Cleaning up Chip3...\n",
      "Cleaning up Chip4...\n",
      "\u001b[92mSystem cleanup completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nETROC COSMIC RUN TEST - QINJ ONLY AND DATA ACQUISITION\")\n",
    "CHARGE_FC = 30 \n",
    "QINJ_COUNT = 1000\n",
    "MANUAL_OFFSET = 50\n",
    "\n",
    "TRIGGER_ENABLE_MASK = 0x8\n",
    "TRIGGER_DATA_SIZE = 1\n",
    "TRIGGER_DELAY_SEL = 472\n",
    "\n",
    "print(\"\\n1. Generating test pixel configuration...\")\n",
    "\n",
    "# Generate random test pixels for each chip\n",
    "test_pixels_per_chip = [\n",
    "    [(randint(0, 15), randint(0, 15))],  # Chip1: 1 pixel\n",
    "    [(randint(0, 15), randint(0, 15)), (randint(0, 15), randint(0, 15))],  # Chip2: 2 pixels\n",
    "    [(randint(0, 15), randint(0, 15)), (randint(0, 15), randint(0, 15))],  # Chip3: 2 pixels\n",
    "    [(randint(0, 15), randint(0, 15))]   # Chip4: 1 pixel\n",
    "]\n",
    "\n",
    "etroc_configs = []\n",
    "for i, (etroc, chip_name) in enumerate(zip(etroc_chips, chip_names)):\n",
    "    if etroc is not None and i < len(test_pixels_per_chip):\n",
    "        etroc_configs.append((etroc, chip_name, test_pixels_per_chip[i]))\n",
    "\n",
    "print(\"Test pixel assignments:\")\n",
    "for etroc, chip_name, pixels in etroc_configs:\n",
    "    print(f\"  {chip_name}: {pixels}\")\n",
    "\n",
    "\n",
    "print(\"\\n2. Calibrating pixel baselines...\")\n",
    "baseline_storage = {}\n",
    "\n",
    "for etroc, chip_name, test_pixels in etroc_configs:\n",
    "    baseline_storage[chip_name] = {}\n",
    "    print(f\"\\nScanning {chip_name}...\")\n",
    "    \n",
    "    for pixel_row, pixel_col in test_pixels:\n",
    "        print(f\"  Calibrating pixel ({pixel_row}, {pixel_col})...\")\n",
    "        \n",
    "        baseline, noise_width = etroc.auto_threshold_scan(\n",
    "            row=pixel_row,\n",
    "            col=pixel_col,\n",
    "            broadcast=False,\n",
    "            offset='auto',\n",
    "            use=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        baseline_storage[chip_name][(pixel_row, pixel_col)] = baseline\n",
    "        print(f\"    Baseline: {baseline:.1f}, Noise width: {noise_width:.1f}\")\n",
    "\n",
    "print(green(\"Baseline calibration completed\"))\n",
    "\n",
    "print(\"\\n3. Configuring pixels for charge injection...\")\n",
    "\n",
    "# Initialize FIFO and reset system\n",
    "df = DataFrame()\n",
    "fifo = FIFO(rb)\n",
    "time.sleep(1)\n",
    "fifo.reset()\n",
    "time.sleep(1)\n",
    "rb.reset_data_error_count()\n",
    "rb.enable_etroc_readout()\n",
    "rb.rerun_bitslip()\n",
    "fifo.use_etroc_data()\n",
    "\n",
    "# Reset and configure all chips\n",
    "for etroc, chip_name, _ in etroc_configs:\n",
    "    print(f\"Resetting {chip_name}...\")\n",
    "    etroc.reset()\n",
    "    etroc.wr_reg(\"singlePort\", 1)\n",
    "    \n",
    "    # Disable all pixels initially\n",
    "    etroc.wr_reg(\"disDataReadout\", 1, broadcast=True)\n",
    "    etroc.wr_reg(\"QInjEn\", 0, broadcast=True)\n",
    "    etroc.wr_reg(\"enable_TDC\", 0, broadcast=True)\n",
    "    etroc.wr_reg(\"disTrigPath\", 1, broadcast=True)\n",
    "    etroc.wr_reg(\"workMode\", 0, broadcast=True)\n",
    "    etroc.wr_reg('triggerGranularity', 1)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Configure specific pixels (skip first chip for trigger-only configuration)\n",
    "for etroc, chip_name, test_pixels in etroc_configs:\n",
    "    print(f\"\\nConfiguring {chip_name} pixels...\")\n",
    "    \n",
    "    for pixel_row, pixel_col in test_pixels:\n",
    "        print(f\"  Configuring pixel ({pixel_row}, {pixel_col})\")\n",
    "        \n",
    "        # Enable pixel for data readout\n",
    "        etroc.wr_reg(\"workMode\", 0, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        etroc.wr_reg(\"enable_TDC\", 1, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        etroc.wr_reg(\"disDataReadout\", 0, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        etroc.wr_reg(\"disTrigPath\", 0, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Set DAC threshold (baseline + margin)\n",
    "        baseline = baseline_storage[chip_name][(pixel_row, pixel_col)]\n",
    "        applied_dac = baseline + MANUAL_OFFSET\n",
    "        etroc.wr_reg('DAC', applied_dac, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        \n",
    "        # Configure charge injection\n",
    "        etroc.wr_reg(\"QSel\", CHARGE_FC - 1, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        etroc.wr_reg(\"QInjEn\", 1, row=pixel_row, col=pixel_col, broadcast=False)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        print(f\"    DAC: {applied_dac}, Charge: {CHARGE_FC} fC\")\n",
    "\n",
    "print(green(\"Pixel configuration completed\"))\n",
    "\n",
    "print(\"\\n4. Configuring self-trigger system...\")\n",
    "\n",
    "rb.kcu.write_node(f\"READOUT_BOARD_{rb.rb}.TRIG_ENABLE_MASK_0\", TRIGGER_ENABLE_MASK)\n",
    "rb.kcu.write_node(f\"READOUT_BOARD_{rb.rb}.TRIG_ENABLE_MASK_1\", TRIGGER_DATA_SIZE)\n",
    "rb.kcu.write_node(f\"READOUT_BOARD_{rb.rb}.TRIG_ENABLE_MASK_3\", TRIGGER_DELAY_SEL)\n",
    "\n",
    "print(f\"Trigger Enable Mask: 0x{TRIGGER_ENABLE_MASK:X}\")\n",
    "print(f\"Trigger Data Size: {TRIGGER_DATA_SIZE}\")\n",
    "print(f\"Trigger Delay Sel: {TRIGGER_DELAY_SEL}\")\n",
    "\n",
    "# check elink status\n",
    "for elink in [0,4,8,12]:\n",
    "    locked = rb.etroc_locked(elink, slave=False)\n",
    "    print(f\"elink: {elink} locked status: {locked}\")\n",
    "\n",
    "rb.enable_etroc_trigger()\n",
    "fifo.reset()\n",
    "time.sleep(1)\n",
    "\n",
    "print(green(\"Self-trigger system configured and enabled\"))\n",
    "\n",
    "print(f\"\\n5. Running data acquisition ({QINJ_COUNT} charge injections)...\")\n",
    "\n",
    "fifo.send_Qinj_only(count=QINJ_COUNT)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    data = fifo.pretty_read(df)\n",
    "    occupancy = len(data)\n",
    "    print(green(f\"✓ FIFO returned {occupancy} data items\"))\n",
    "    \n",
    "    if occupancy > 0:\n",
    "        \n",
    "        print(\"\\n6. Analyzing data...\")\n",
    "        \n",
    "        # Initialize data structures\n",
    "        chip_hits = {}\n",
    "        chip_data = {}\n",
    "        \n",
    "        for etroc, chip_name, test_pixels in etroc_configs:\n",
    "            chip_hits[chip_name] = {}\n",
    "            chip_data[chip_name] = {}\n",
    "            for pixel in test_pixels:\n",
    "                chip_hits[chip_name][pixel] = 0\n",
    "                chip_data[chip_name][pixel] = {'toa': [], 'tot': [], 'cal': []}\n",
    "        \n",
    "        # Parse data\n",
    "        header_count = hit_counter = filler_count = trailer_count = 0\n",
    "        \n",
    "        for i, event in enumerate(data):\n",
    "            if event is None or len(event) < 2:\n",
    "                continue\n",
    "            \n",
    "            data_type, event_data = event[0], event[1]\n",
    "            \n",
    "            if data_type == 'header':\n",
    "                header_count += 1\n",
    "            elif data_type == 'filler':\n",
    "                filler_count += 1\n",
    "            elif data_type == 'trailer':\n",
    "                trailer_count += 1\n",
    "            elif data_type == 'data':\n",
    "                hit_counter += 1\n",
    "                \n",
    "                # Extract hit information\n",
    "                toa = event_data.get('toa')\n",
    "                tot = event_data.get('tot')\n",
    "                cal = event_data.get('cal')\n",
    "                row = event_data.get('row_id')\n",
    "                col = event_data.get('col_id')\n",
    "                \n",
    "                # Match to configured pixels\n",
    "                for etroc, chip_name, test_pixels in etroc_configs:\n",
    "                    if (row, col) in test_pixels:\n",
    "                        chip_hits[chip_name][(row, col)] += 1\n",
    "                        chip_data[chip_name][(row, col)]['toa'].append(toa)\n",
    "                        chip_data[chip_name][(row, col)]['tot'].append(tot)\n",
    "                        chip_data[chip_name][(row, col)]['cal'].append(cal)\n",
    "                        \n",
    "                        # Show first few hits\n",
    "                        if chip_hits[chip_name][(row, col)] <= 2:\n",
    "                            print(green(f\"  {chip_name} Pixel({row},{col}) Hit {chip_hits[chip_name][(row, col)]}: \"\n",
    "                                      f\"ToA={toa}, ToT={tot}, Cal={cal}\"))\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nAcquisition Summary:\")\n",
    "        print(f\"  Total events: {len(data)}\")\n",
    "        print(f\"  Headers: {header_count}\")\n",
    "        print(f\"  Hits: {hit_counter}\")\n",
    "        print(f\"  Trailers: {trailer_count}\")\n",
    "        print(f\"  Fillers: {filler_count}\")\n",
    "        \n",
    "        # Calculate and display pixel statistics\n",
    "        print(f\"\\nPixel Performance Results:\")\n",
    "        test_results = {\n",
    "            \"test_parameters\": {\n",
    "                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "                \"charge_fC\": CHARGE_FC,\n",
    "                \"qinj_count\": QINJ_COUNT,\n",
    "                \"num_ETROCs\": len(etroc_configs)\n",
    "            },\n",
    "            \"chip_results\": {},\n",
    "            \"parsed_hits\": [event[1] for event in data if event[0] == 'data'],\n",
    "            \"raw_events\": data\n",
    "        }\n",
    "        \n",
    "        for etroc, chip_name, test_pixels in etroc_configs:\n",
    "            for pixel in test_pixels:\n",
    "                pixel_row, pixel_col = pixel\n",
    "                hits = chip_hits[chip_name][pixel]\n",
    "                \n",
    "                if hits > 0:\n",
    "                    toa_mean = np.mean(chip_data[chip_name][pixel]['toa'])\n",
    "                    tot_mean = np.mean(chip_data[chip_name][pixel]['tot'])\n",
    "                    cal_mean = np.mean(chip_data[chip_name][pixel]['cal'])\n",
    "                    \n",
    "                    print(green(f\"  {chip_name} Pixel({pixel_row},{pixel_col}): {hits} hits, \"\n",
    "                              f\"ToA={toa_mean:.1f}, ToT={tot_mean:.1f}, Cal={cal_mean:.1f}\"))\n",
    "                    \n",
    "                    # Store results\n",
    "                    test_results[\"chip_results\"][f\"{chip_name}_pixel_{pixel_row}_{pixel_col}\"] = {\n",
    "                        \"chip\": chip_name,\n",
    "                        \"position\": pixel,\n",
    "                        \"hits\": hits,\n",
    "                        \"stats\": {\n",
    "                            \"toa_mean\": toa_mean,\n",
    "                            \"tot_mean\": tot_mean,\n",
    "                            \"cal_mean\": cal_mean\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    print(red(f\"  {chip_name} Pixel({pixel_row},{pixel_col}): No hits detected\"))\n",
    "        \n",
    "        # ============================================================================\n",
    "        # 7. SAVE RESULTS\n",
    "        # ============================================================================\n",
    "        \n",
    "        print(\"\\n7. Saving results...\")\n",
    "        output_dir = \"Qinj_Output\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        filename = f\"cosmic_run_{len(etroc_configs)}_chips_{timestamp}.pkl\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(test_results, f)\n",
    "            print(green(f\"Results saved to {filepath}\"))\n",
    "        except Exception as e:\n",
    "            print(red(f\"Failed to save results: {e}\"))\n",
    "            \n",
    "    else:\n",
    "        print(red(\"No data received from FIFO\"))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(red(f\"Data acquisition failed: {e}\"))\n",
    "\n",
    "# ============================================================================\n",
    "# 8. CLEANUP SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n8. Cleaning up system...\")\n",
    "\n",
    "for etroc, chip_name, _ in etroc_configs:\n",
    "    print(f\"Cleaning up {chip_name}...\")\n",
    "    for _ in range(3):\n",
    "        fifo.reset()\n",
    "        rb.reset_data_error_count()\n",
    "        etroc.wr_reg(\"QInjEn\", 0, broadcast=True)\n",
    "        etroc.wr_reg(\"disDataReadout\", 1, broadcast=True)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(green(\"System cleanup completed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4099b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ETROC COSMIC RUN DATA ANALYSIS\")\n",
    "\n",
    "# Change this to your data file path\n",
    "FILEPATH = \"Cosmic_Output/cosmic_run_4_chips_2025-07-10_01-54-17.pkl\"\n",
    "\n",
    "# Display options\n",
    "SHOW_HIT_SAMPLES = 10           # Number of sample hits to show (0 = show all)\n",
    "SHOW_EVENT_SAMPLES = 10         # Number of sample events to show (0 = show all)\n",
    "SHOW_OPTIMIZED_SUMMARY = True   # Show additional optimized analysis\n",
    "\n",
    "with open(FILEPATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "if data is not None:\n",
    "    print(\"=== ALL PARAMETERS ===\\n\")\n",
    "  \n",
    "    for main_key in ['test_parameters', 'parsed_hits', 'raw_events', 'chip_results']:\n",
    "        print(f\" {main_key.upper().replace('_', ' ')}:\")\n",
    "        \n",
    "        if main_key in data:\n",
    "            if main_key == 'parsed_hits':\n",
    "                print(f\"   Count: {len(data[main_key])}\")\n",
    "                \n",
    "                # Show sample hits or all hits based on setting\n",
    "                hits_to_show = data[main_key]\n",
    "                if SHOW_HIT_SAMPLES > 0:\n",
    "                    hits_to_show = hits_to_show[:SHOW_HIT_SAMPLES]\n",
    "                \n",
    "                for i, hit in enumerate(hits_to_show):\n",
    "                    print(f\"   Hit {i+1}: {hit}\")\n",
    "                \n",
    "                if SHOW_HIT_SAMPLES > 0 and len(data[main_key]) > SHOW_HIT_SAMPLES:\n",
    "                    print(f\"   ... and {len(data[main_key]) - SHOW_HIT_SAMPLES} more hits\")\n",
    "                    \n",
    "            elif main_key == 'raw_events':\n",
    "                print(f\"   Count: {len(data[main_key])}\")\n",
    "                \n",
    "                # Show sample events or all events based on setting\n",
    "                events_to_show = data[main_key]\n",
    "                if SHOW_EVENT_SAMPLES > 0:\n",
    "                    events_to_show = events_to_show[:SHOW_EVENT_SAMPLES]\n",
    "                \n",
    "                for i, event in enumerate(events_to_show):\n",
    "                    print(f\"   Event {i+1}: {event}\")\n",
    "                \n",
    "                if SHOW_EVENT_SAMPLES > 0 and len(data[main_key]) > SHOW_EVENT_SAMPLES:\n",
    "                    print(f\"   ... and {len(data[main_key]) - SHOW_EVENT_SAMPLES} more events\")\n",
    "            \n",
    "            # Check if data is a dictionary\n",
    "            elif isinstance(data[main_key], dict):\n",
    "                for key, value in data[main_key].items():\n",
    "                    print(f\"   {key}: {value}\")\n",
    "            else:\n",
    "                print(f\"   {data[main_key]}\")\n",
    "        else:\n",
    "            print(\"   Not found\")\n",
    "        \n",
    "        print()  # Empty line between sections\n",
    "\n",
    "    \n",
    "    if SHOW_OPTIMIZED_SUMMARY:\n",
    "        \n",
    "        if 'raw_events' in data:\n",
    "            events = data['raw_events']\n",
    "            event_types = {}\n",
    "            for event in events:\n",
    "                if event and len(event) >= 1:\n",
    "                    event_type = event[0]\n",
    "                    event_types[event_type] = event_types.get(event_type, 0) + 1\n",
    "            \n",
    "            print(\"\\nEvent Type Distribution:\")\n",
    "            for event_type, count in event_types.items():\n",
    "                percentage = (count / len(events)) * 100 if events else 0\n",
    "                print(f\"  {event_type.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Hit analysis by elink\n",
    "        if 'parsed_hits' in data:\n",
    "            hits = data['parsed_hits']\n",
    "            elink_hits = {}\n",
    "            pixel_hits = {}\n",
    "            \n",
    "            for hit in hits:\n",
    "                elink = hit.get('elink', 'Unknown')\n",
    "                row = hit.get('row_id', 'N/A')\n",
    "                col = hit.get('col_id', 'N/A')\n",
    "                \n",
    "                elink_hits[elink] = elink_hits.get(elink, 0) + 1\n",
    "                pixel_key = f\"({row},{col})\"\n",
    "                pixel_hits[pixel_key] = pixel_hits.get(pixel_key, 0) + 1\n",
    "            \n",
    "            print(f\"\\nHits by E-link:\")\n",
    "            for elink in sorted(elink_hits.keys()):\n",
    "                print(f\"  Elink {elink}: {elink_hits[elink]} hits\")\n",
    "            \n",
    "            print(f\"\\nHits by Pixel:\")\n",
    "            for pixel, count in sorted(pixel_hits.items()):\n",
    "                print(f\"  Pixel {pixel}: {count} hits\")\n",
    "        \n",
    "        if 'parsed_hits' in data:\n",
    "            hits = data['parsed_hits']\n",
    "            toa_values = [hit.get('toa') for hit in hits if hit.get('toa') is not None]\n",
    "            tot_values = [hit.get('tot') for hit in hits if hit.get('tot') is not None]\n",
    "            cal_values = [hit.get('cal') for hit in hits if hit.get('cal') is not None]\n",
    "            \n",
    "            print(f\"\\nTiming Statistics:\")\n",
    "            if toa_values:\n",
    "                print(f\"  ToA: min={min(toa_values)}, max={max(toa_values)}, \"\n",
    "                      f\"mean={np.mean(toa_values):.1f}, std={np.std(toa_values):.1f}\")\n",
    "            if tot_values:\n",
    "                print(f\"  ToT: min={min(tot_values)}, max={max(tot_values)}, \"\n",
    "                      f\"mean={np.mean(tot_values):.1f}, std={np.std(tot_values):.1f}\")\n",
    "            if cal_values:\n",
    "                print(f\"  Cal: min={min(cal_values)}, max={max(cal_values)}, \"\n",
    "                      f\"mean={np.mean(cal_values):.1f}, std={np.std(cal_values):.1f}\")\n",
    "        \n",
    "        if 'test_parameters' in data and 'chip_results' in data:\n",
    "            params = data['test_parameters']\n",
    "            total_hits = sum(result.get('hits', 0) for result in data['chip_results'].values())\n",
    "            injections = params.get('qinj_count', params.get('Qinj_cnt', 1))\n",
    "            n_pixels = len(data['chip_results'])\n",
    "            \n",
    "            expected_hits = injections * n_pixels\n",
    "            efficiency = (total_hits / expected_hits * 100) if expected_hits > 0 else 0\n",
    "            \n",
    "            print(f\"\\nTest Efficiency:\")\n",
    "            print(f\"  Expected hits: {expected_hits} ({injections} inj × {n_pixels} pixels)\")\n",
    "            print(f\"  Actual hits: {total_hits}\")\n",
    "            print(f\"  Efficiency: {efficiency:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n❌ Failed to load data. Please check the file path.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "print(\"ETROC COSMIC RUN DATA ANALYSIS\")\n",
    "\n",
    "# Change this to your data file path\n",
    "FILEPATH = \"Cosmic_Data_Chunks/session_20250715_115843/chunk_0000.pkl\"\n",
    "\n",
    "# Display options\n",
    "SHOW_HIT_SAMPLES = 10           # Number of sample hits to show (0 = show all)\n",
    "SHOW_EVENT_SAMPLES = 10         # Number of sample events to show (0 = show all)\n",
    "SHOW_OPTIMIZED_SUMMARY = True   # Show additional optimized analysis\n",
    "\n",
    "with open(FILEPATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "if data is not None:\n",
    "    print(\"=== ALL PARAMETERS ===\\n\")\n",
    "\n",
    "    for main_key in ['test_parameters', 'statistics', 'parsed_hits', 'raw_events']:\n",
    "        print(f\" {main_key.upper().replace('_', ' ')}:\")\n",
    "        \n",
    "        if main_key in data:\n",
    "            if main_key == 'parsed_hits':\n",
    "                print(f\"   Count: {len(data[main_key])}\")\n",
    "\n",
    "                hits_to_show = data[main_key]\n",
    "                if SHOW_HIT_SAMPLES > 0:\n",
    "                    hits_to_show = hits_to_show[:SHOW_HIT_SAMPLES]\n",
    "                \n",
    "                for i, hit in enumerate(hits_to_show):\n",
    "                    print(f\"   Hit {i+1}: {hit}\")\n",
    "                \n",
    "                if SHOW_HIT_SAMPLES > 0 and len(data[main_key]) > SHOW_HIT_SAMPLES:\n",
    "                    print(f\"   ... and {len(data[main_key]) - SHOW_HIT_SAMPLES} more hits\")\n",
    "                    \n",
    "            elif main_key == 'raw_events':\n",
    "                print(f\"   Count: {len(data[main_key])}\")\n",
    "\n",
    "                events_to_show = data[main_key]\n",
    "                if SHOW_EVENT_SAMPLES > 0:\n",
    "                    events_to_show = events_to_show[:SHOW_EVENT_SAMPLES]\n",
    "                \n",
    "                for i, event in enumerate(events_to_show):\n",
    "                    print(f\"   Event {i+1}: {event}\")\n",
    "                \n",
    "                if SHOW_EVENT_SAMPLES > 0 and len(data[main_key]) > SHOW_EVENT_SAMPLES:\n",
    "                    print(f\"   ... and {len(data[main_key]) - SHOW_EVENT_SAMPLES} more events\")\n",
    "            \n",
    "            # Check if data is a dictionary\n",
    "            elif isinstance(data[main_key], dict):\n",
    "                for key, value in data[main_key].items():\n",
    "                    print(f\"   {key}: {value}\")\n",
    "            else:\n",
    "                print(f\"   {data[main_key]}\")\n",
    "        else:\n",
    "            print(\"   Not found\")\n",
    "        \n",
    "        print()  # Empty line between sections\n",
    "\n",
    "    if 'chip_results' in data:\n",
    "        print(\" CHIP RESULTS (LEGACY):\")\n",
    "        chip_results = data['chip_results']\n",
    "        if isinstance(chip_results, dict):\n",
    "            for key, value in chip_results.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "        print()\n",
    "    \n",
    "    if SHOW_OPTIMIZED_SUMMARY:\n",
    "        \n",
    "        if 'raw_events' in data:\n",
    "            events = data['raw_events']\n",
    "            event_types = {}\n",
    "            for event in events:\n",
    "                if event and len(event) >= 1:\n",
    "                    event_type = event[0]\n",
    "                    event_types[event_type] = event_types.get(event_type, 0) + 1\n",
    "            \n",
    "            print(\"\\nEvent Type Distribution:\")\n",
    "            for event_type, count in event_types.items():\n",
    "                percentage = (count / len(events)) * 100 if events else 0\n",
    "                print(f\"  {event_type.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Hit analysis by elink\n",
    "        if 'parsed_hits' in data:\n",
    "            hits = data['parsed_hits']\n",
    "            elink_hits = {}\n",
    "            pixel_hits = {}\n",
    "            \n",
    "            for hit in hits:\n",
    "                elink = hit.get('elink', 'Unknown')\n",
    "                row = hit.get('row_id', 'N/A')\n",
    "                col = hit.get('col_id', 'N/A')\n",
    "                \n",
    "                elink_hits[elink] = elink_hits.get(elink, 0) + 1\n",
    "                pixel_key = f\"({row},{col})\"\n",
    "                pixel_hits[pixel_key] = pixel_hits.get(pixel_key, 0) + 1\n",
    "            \n",
    "            print(f\"\\nHits by E-link:\")\n",
    "            for elink in sorted(elink_hits.keys()):\n",
    "                print(f\"  Elink {elink}: {elink_hits[elink]} hits\")\n",
    "            \n",
    "            print(f\"\\nHits by Pixel (showing top 20):\")\n",
    "            sorted_pixels = sorted(pixel_hits.items(), key=lambda x: x[1], reverse=True)\n",
    "            for i, (pixel, count) in enumerate(sorted_pixels[-20:]):\n",
    "                print(f\"  {i+1}. Pixel {pixel}: {count} hits\")\n",
    "            \n",
    "            if len(sorted_pixels) > 20:\n",
    "                print(f\"  ... and {len(sorted_pixels) - 20} more pixels with hits\")\n",
    "        \n",
    "        if 'parsed_hits' in data:\n",
    "            hits = data['parsed_hits']\n",
    "            toa_values = [hit.get('toa') for hit in hits if hit.get('toa') is not None]\n",
    "            tot_values = [hit.get('tot') for hit in hits if hit.get('tot') is not None]\n",
    "            cal_values = [hit.get('cal') for hit in hits if hit.get('cal') is not None]\n",
    "            \n",
    "            print(f\"\\nTiming Statistics:\")\n",
    "            if toa_values:\n",
    "                print(f\"  ToA: min={min(toa_values)}, max={max(toa_values)}, \"\n",
    "                      f\"mean={np.mean(toa_values):.1f}, std={np.std(toa_values):.1f}\")\n",
    "            if tot_values:\n",
    "                print(f\"  ToT: min={min(tot_values)}, max={max(tot_values)}, \"\n",
    "                      f\"mean={np.mean(tot_values):.1f}, std={np.std(tot_values):.1f}\")\n",
    "            if cal_values:\n",
    "                print(f\"  Cal: min={min(cal_values)}, max={max(cal_values)}, \"\n",
    "                      f\"mean={np.mean(cal_values):.1f}, std={np.std(cal_values):.1f}\")\n",
    "        \n",
    "        if 'test_parameters' in data:\n",
    "            params = data['test_parameters']\n",
    "            if 'parsed_hits' in data:\n",
    "                total_hits = len(data['parsed_hits'])\n",
    "                total_time = params.get('total_time_seconds', 0)\n",
    "                total_pixels = params.get('total_pixels', 0)\n",
    "                \n",
    "                print(f\"\\nCosmic Ray Detection Summary:\")\n",
    "                print(f\"  Total running time: {total_time:.1f} seconds\")\n",
    "                print(f\"  Total cosmic hits: {total_hits}\")\n",
    "                if total_time > 0:\n",
    "                    print(f\"  Hit rate: {total_hits/total_time:.3f} hits/second\")\n",
    "                if total_pixels > 0:\n",
    "                    print(f\"  Hit rate per pixel: {total_hits/total_pixels:.3f} hits/pixel\")\n",
    "                    if total_time > 0:\n",
    "                        print(f\"  Hit rate per pixel per second: {total_hits/(total_pixels*total_time):.6f} hits/pixel/second\")\n",
    "\n",
    "                if 'failed_pixels_from_baseline' in params:\n",
    "                    failed_pixels = params['failed_pixels_from_baseline']\n",
    "                    total_failed = sum(len(failed_list) for failed_list in failed_pixels.values())\n",
    "                    if total_failed > 0:\n",
    "                        print(f\"\\nBaseline Scan Issues:\")\n",
    "                        print(f\"  Total pixels with scan failures: {total_failed}\")\n",
    "                        for chip_name, failed_list in failed_pixels.items():\n",
    "                            if failed_list:\n",
    "                                print(f\"  {chip_name}: {len(failed_list)} failed pixels {failed_list}\")\n",
    "                    else:\n",
    "                        print(f\"\\nBaseline Scan: All sample pixels passed\")\n",
    "\n",
    "        if 'statistics' in data:\n",
    "            stats = data['statistics']\n",
    "            print(f\"\\nDetailed Statistics:\")\n",
    "            for key, value in stats.items():\n",
    "                if key not in ['pixel_hits', 'elink_hits']:\n",
    "                    print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n❌ Failed to load data. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24070c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful loaded meta data file: Cosmic_Data_Chunks/session_20250715_120116/metadata.pkl\n",
      "data type: <class 'dict'>\n",
      "\n",
      "=== contents ===\n",
      "  total_events: 26824496\n",
      "  total_chunks: 56\n",
      "  chunk_size: 500000\n",
      "  session_dir: Cosmic_Data_Chunks/session_20250715_120116\n",
      "  timestamp: 2025-07-15T12:34:03.970526\n",
      "reading chucnk file now--\n",
      "Loaded chucnk file: Cosmic_Data_Chunks/session_20250724_130428/chunk_0000.pkl\n",
      "data type: <class 'list'>\n",
      "Event number: 16379\n",
      "\n",
      "first 10 events:\n",
      "  events 1: <class 'tuple'> - ('header', {'elink': 0, 'sof': 1, 'eof': 0, 'full': 0, 'any_full': 0, 'global_full': 0, 'l1counter': 49, 'type': 0, 'bcid': 3014, 'raw': '0x3c5c0c4bc6', 'raw_full': '0x1003c5c0c4bc6', 'meta': '0x100'})\n",
      "  events 2: <class 'tuple'> - ('trailer', {'elink': 0, 'sof': 0, 'eof': 1, 'full': 0, 'any_full': 0, 'global_full': 0, 'chipid': 0, 'status': 0, 'hits': 0, 'crc': 119, 'raw': '0x77', 'raw_full': '0x2000000000077', 'meta': '0x200'})\n",
      "  events 3: <class 'tuple'> - ('header', {'elink': 4, 'sof': 1, 'eof': 0, 'full': 0, 'any_full': 0, 'global_full': 0, 'l1counter': 76, 'type': 0, 'bcid': 3014, 'raw': '0x3c5c130bc6', 'raw_full': '0x1043c5c130bc6', 'meta': '0x104'})\n",
      "  events 4: <class 'tuple'> - ('data', {'ea': 0, 'col_id': 1, 'row_id': 0, 'toa': 210, 'cal': 148, 'tot': 49, 'elink': 4, 'full': 0, 'any_full': 0, 'global_full': 0, 'raw': '0x820690c494', 'raw_full': '0x4820690c494', 'meta': '0x4'})\n",
      "  events 5: <class 'tuple'> - ('data', {'ea': 0, 'col_id': 0, 'row_id': 0, 'toa': 205, 'cal': 147, 'tot': 45, 'elink': 4, 'full': 0, 'any_full': 0, 'global_full': 0, 'raw': '0x800668b493', 'raw_full': '0x4800668b493', 'meta': '0x4'})\n",
      "  events 6: <class 'tuple'> - ('trailer', {'elink': 4, 'sof': 0, 'eof': 1, 'full': 0, 'any_full': 0, 'global_full': 0, 'chipid': 0, 'status': 0, 'hits': 2, 'crc': 173, 'raw': '0x2ad', 'raw_full': '0x20400000002ad', 'meta': '0x204'})\n",
      "  events 7: <class 'tuple'> - ('header', {'elink': 8, 'sof': 1, 'eof': 0, 'full': 0, 'any_full': 0, 'global_full': 0, 'l1counter': 206, 'type': 0, 'bcid': 3014, 'raw': '0x3c5c338bc6', 'raw_full': '0x1083c5c338bc6', 'meta': '0x108'})\n",
      "  events 8: <class 'tuple'> - ('data', {'ea': 0, 'col_id': 1, 'row_id': 0, 'toa': 233, 'cal': 150, 'tot': 58, 'elink': 8, 'full': 0, 'any_full': 0, 'global_full': 0, 'raw': '0x820748e896', 'raw_full': '0x8820748e896', 'meta': '0x8'})\n",
      "  events 9: <class 'tuple'> - ('data', {'ea': 0, 'col_id': 0, 'row_id': 0, 'toa': 225, 'cal': 149, 'tot': 56, 'elink': 8, 'full': 0, 'any_full': 0, 'global_full': 0, 'raw': '0x800708e095', 'raw_full': '0x8800708e095', 'meta': '0x8'})\n",
      "  events 10: <class 'tuple'> - ('trailer', {'elink': 8, 'sof': 0, 'eof': 1, 'full': 0, 'any_full': 0, 'global_full': 0, 'chipid': 0, 'status': 0, 'hits': 2, 'crc': 225, 'raw': '0x2e1', 'raw_full': '0x20800000002e1', 'meta': '0x208'})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "METADATA_FILE = \"Cosmic_Data_Chunks/session_20250715_120116/metadata.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(METADATA_FILE, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    print(f\"Successful loaded meta data file: {METADATA_FILE}\")\n",
    "    print(f\"data type: {type(metadata)}\")\n",
    "    \n",
    "    if isinstance(metadata, dict):\n",
    "        print(f\"\\n=== contents ===\")\n",
    "        for key, value in metadata.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"can't find file: {METADATA_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"reading chucnk file now--\")\n",
    "CHUNK_FILE = \"Cosmic_Data_Chunks/session_20250724_130428/chunk_0000.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(CHUNK_FILE, 'rb') as f:\n",
    "        chunk_data = pickle.load(f)\n",
    "    \n",
    "    print(f\"Loaded chucnk file: {CHUNK_FILE}\")\n",
    "    print(f\"data type: {type(chunk_data)}\")\n",
    "    print(f\"Event number: {len(chunk_data) if hasattr(chunk_data, '__len__') else '无法计算'}\")\n",
    "    \n",
    "    if hasattr(chunk_data, '__len__') and len(chunk_data) > 0:\n",
    "        print(f\"\\nfirst 10 events:\")\n",
    "        for i, event in enumerate(chunk_data[:10]):\n",
    "            print(f\"  events {i+1}: {type(event)} - {event}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"could not find file: {CHUNK_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
